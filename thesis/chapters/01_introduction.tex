\section{Introduction}
\label{cha:introduction}

Spatio-temporal databases are increasing in popularity due to increased production of such data by smart cities, personal light electric vehicles and numerous IoT devices.
As the need for such databases raises, developers reach for production ready, scalable solutions.
One of spatiotemporal databases is MobilityDB, built on top of the spatial extension PostGIS, extends PostgreSQL's capabilities regarding spatio-temporal aspects~\parencite{zimanyiMobilityDBMobilityDatabase2020}.
Previous research has shown that MobilityDB can also scale horizontally using another extension, Citus~\parencite{bakliDistributedMobilityData2020, bakliDistributedMovingObject2019, cubukcuCitusDistributedPostgreSQL2021}.
In this thesis we will refer to distributed MobilityDB using Citus as MobilityDBC.
As a comparison, CrateDB is a natively distributable SQL database designed for scalability, high performance, and real-time applications.
Both of the solutions are open source.

While the runtimes of specific queries of BerlinMOD benchmark by \textcite{duntgenBerlinMODBenchmarkMoving2009} have been evaluated on 4 and 28 node clusters of \mobilitydbc~by \parencite{bakliDistributedMobilityData2020}, its horizontal and vertical scalability still remains underexplored.
Previous research mostly focuses on designing queries for single node systems, and often does not compare systems between one another.
The other system, CrateDB, also has not been fully evaluated for its usability in spatiotemporal use cases.
Moreover, benchmarking with a wider range of cluster sizes is necessary to establish the scalability pattern.
Additionally, a comparison between \mobilitydbc and CrateDB in terms of horizontal scalability has not been conducted, which could provide valuable insights into their respective strengths and weaknesses.

We therefore make the following contributions in this thesis:
\begin{enumerate}
	\item We discuss the unique value propositions of MobilityDBC and CrateDB (\cref{cha:background})
	\item We design a benchmark of common functionality of both databases that addresses the scalability according to requirements we have identified (\cref{cha:benchmarkdesign})
	\item We implement the benchmark according to our design (\cref{sec:implementation})
	\item We use our implementation to run the benchmark on both databases on 2 cluster sizes, analyze and explain the results (\cref{sec:experiment})
	\item We critically evaluate our design and evaluation, discussing potential limitations (\cref{cha:discussion})
\end{enumerate}

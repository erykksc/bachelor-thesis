\section{Introduction}
\label{cha:introduction}

Spatio-temporal databases are increasing in popularity due to increased production of such data by smart cities, personal light electric vehicles and numerous IoT devices.
As the need for such databases raises, developers reach for production ready, scalable solutions.
One of spatiotemporal databases is MobilityDB, built on top of the spatial extension PostGIS, extends PostgreSQL's capabilities regarding spatio-temporal aspects~\parencite{zimanyiMobilityDBMobilityDatabase2020}.
Previous research has shown that MobilityDB can also scale horizontally using another extension, Citus~\parencite{bakliDistributedMobilityData2020, bakliDistributedMovingObject2019, cubukcuCitusDistributedPostgreSQL2021}.
In this thesis we will refer to distributed MobilityDB using Citus as \mobilitydbc.
As a comparison, CrateDB is a natively distributable SQL database designed for scalability, high performance, and real-time applications.
Both of the solutions are open source.

While the runtimes of specific queries of BerlinMOD benchmark by \textcite{duntgenBerlinMODBenchmarkMoving2009} have been evaluated on 4 and 28 node clusters of \mobilitydbc~by \parencite{bakliDistributedMobilityData2020}, its horizontal and vertical scalability still remains underexplored.
Previous research mostly focuses on designing queries for single node systems, and often does not compare systems between one another.
The other system, CrateDB, also has not been fully evaluated for its usability in spatiotemporal use cases.
Moreover, benchmarking with a wider range of cluster sizes is necessary to establish the scalability pattern.
Additionally, a comparison between \mobilitydbc and CrateDB in terms of horizontal scalability has not been conducted, which could provide valuable insights into their respective strengths and weaknesses.

We therefore make the following contributions in this thesis:
\begin{enumerate}
	\item We discuss the unique value propositions of both databases (\cref{cha:background})
	\item We design and implement a benchmark of common functionality of both databases that addresses the scalability according to requirements we have identified (\cref{cha:benchmarkdesign})
	\item We setup and run the experiment on 4 cluster sizes using our custom benchmark (\cref{cha:evaluation})
	\item We analyze the results for scalability patterns and discuss the results of the benchmark (\cref{cha:evaluation})
\end{enumerate}

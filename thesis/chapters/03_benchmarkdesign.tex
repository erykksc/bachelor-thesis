\section{Benchmark Design}
\label{cha:benchmarkdesign}

In this thesis we compare two DDBMSs, CrateDB and \mobilitydbc to assess their scalability in spatial-temporal workloads typical for IoT usecases.
Spatio-temporal aspects are our primary target as the value proposition of \mobilitydbc is exactly that.
Our goal is not to advocate for one system over the other but to investigate their respective strengths and limitation in processing ST data at scale.
To evaluate the scalability we have designed a benchmark seen in Figure~\ref{fig:benchmark_design}.

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}[
			font=\small,
			node distance=0.5cm,
			box/.style={
					rectangle,
					draw,
					text width=2.5cm,
					minimum height=1cm,
					align=center
				},
			client/.style={
					box,
					fill=blue!10,
					draw=blue!70
				},
			coordinator/.style={
					box,
					fill=orange!10,
					draw=orange!70,
				},
			worker/.style={
					box,
					fill=purple!10,
					draw=purple!70
				},
			group/.style={
					rectangle,
					draw,
					dashed,
					inner sep=0.2cm
				},
			arrow/.style={
					->,
					>=latex
				}
		]
		% Client components
		\node[client] (db_client) {\textbf{DB Client}};
		\node[client, below=of db_client] (datagen) {Data Generator};
		% Client connections
		\draw[arrow] (datagen) -- (db_client);
		% Coordinator node
		\node[coordinator, right=5cm of db_client] (cn) {
			\textbf{Master Node}};
		% Worker nodes
		\node[worker, below=of cn] (w2) {
			\textbf{Worker Node \\ 2}};
		\node[worker, left=of w2] (w1) {
			\textbf{Worker Node \\ 1}};
		\node[worker, right=of w2] (w3) {
			\textbf{Worker Node \\ N}};
		% Connections of coordinator to workers
		\draw[arrow] (cn) -- (w1);
		\draw[arrow] (cn) -- (w2);
		\draw[arrow] (cn) -- (w3);
		% Client to SUT connections
		\draw[arrow] (db_client) to[bend left=13] node[above] {Queries/Writes} (cn);
		\draw[arrow] (cn) to[bend left=5] node[below] {Results} (db_client);

		% Group boxes
		\begin{pgfonlayer}{background}
			% Benchmarking client
			\node[group, fit=(db_client) (datagen)] (client) {};
			\node[above] at (client.north) {Load generator};

			% System Under test
			\node[group, fit=(cn) (w1) (w2) (w3)] (sut) {};
			\node[above] at (sut.north) {System Under Test};
		\end{pgfonlayer}
	\end{tikzpicture}
	\caption{
		Load generator will write generated spatiotemporal data and execute
		the workload against System Under Test (MobilityDB/CrateDB cluster).
	}
	\label{fig:benchmark_design}
\end{figure}

In the benchmark the load generator will connect with the System Under Test (SUT) and issue queries.
It will log metrics allowing later analysis of the findings.
The System Under Test, will be run on the same resources i.e., MobilityDB will be deployed on the same resources as CrateDB.
The resources for the SUT will be restarted between each benchmark run.

% Things to explain:
% * this benchmark is designed for cloud
\subsection{Infrastructure}
We design this benchmark to be deployed and run on the cloud for two reasons.
Firstly, we did not have access to multiple local machines with the same specification to ensure no bottlenecks.
Secondly, the repeatability and relevance of such approach is improved, as the benchmark can be replicated by other parties without them having access to a collection of devices and cloud deployed systems are a common (CITATION).

% * this benchmark uses infrastructure as code to allow reproducibility
% * this benchmark each ddbms is run on a Kubernetes cluster
To improve reproducibility and repeatability all parts of the benchmark are documented in code, this includes the resources deploy on the cloud.
Using infrastructure as code allows multiple benchmark runs with the exact same configuration without option of skipping checking in some setting on a cloud provider web admin console.

% * explain that both ddbms will be run on the same resources (same vm sizes)
Using cloud and infrastructure as code allows us to deploy both CrateDB and MobilityDB on the exact same resources with the same configuration of them i.e., same virtual machine types/sizes.
This allows us to be fair towards both systems and provide them with the same resources.

\subsection{DDBMS cluster}
Documenting the DDBMS configuration through Kubernetes deployment files ensures that the software will be deployed with the same settings and versions using versioned container images.
Additionally by using Kubernetes, the benchmark can also be more easily developed on a local systems by using contenerization.
The local development has been an important consideration as the recent withdraw of google from issuing cloud tokens to our university, lead to uncertainty to where the benchmark will be deployed.
Kubernetes has been chosen over using bash scripts for installing DDBMS on multiple virtual machines for three reasons.
(1) It allows easier deployment of a DDBMS cluster, which is beneficial when deploying multiple cluster sizes and resetting their state by destroying them.
(2) The opportunity to experiment with a new technology also played a role, as we were unfamiliar with working with Kubernetes before.
(3) Relevancy, as deployment of such clustered DDBMS systems is often done this way in production environments (CITATION HERE)


\subsection{Load generator}
% * this benchmark uses synthetic workoad load generator
We decided to split the benchmark into two major components, the DDBMS cluster and a load generator.
Load generator will be a software simulating multiple clients on a DDBMS cluster by using multiple threads.
It will use a closed synthetic workload generation with fixed user pool with requests with random parameters generated on the fly based on query templates.
By using a synthetic workload we sacrifice the realism of the application by improving understandability and simplifying the development of the benchmark.
This approach allows easy data collection, compared to using multiple load generators running on multiple hosts and makes the benchmark cheaper to run.
We believe this strategy is viable, as the load generator primarily issues requests, which are i/o heavy, so the performance of the computer running the software shouldn't be a bottleneck.
Simulating multiple clients at the same time strives to mimic the IOT workload where there are many devices issuing requests at the same time.
% * this benchmark load generator is placed on the same VPC in the cloud as the cluster with running DDBMS
The load generator is also put on the cloud in the same virtual private cloud (VPC) as the DDBMS cluster.
Putting the load generator next to the SUT instead of running it on our local computer allows us to minimize latency and potential disturbances while the benchmark runs i.e., packages dropped due to network problems.


\subsection{Workloads and metrics}
% * explain which metrics have been chosen and why:
%   - latency
%   - throughput
%   - success rate (to see whether the system answers all queries and doesn't drop them)
During the benchmark run, the load generator will log the following metrics for the analysis afterwards:
(1) Latency in milliseconds between sending the request to DDBMS and receiving a response.
(2) Whether the request/query has been resolved successfully or not.
This allows us to avoid a situation where one SUT would perform better by rejecting multiple queries.
(3) Throughput, by logging how many queries have been sent and the total time it took to do it, we will calculate the throughput.
We chose this metric as it is an important in IOT devices as they are commonly deployed in great amounts and send a lot of data i.e., shareable e-scooters in a city which report their location and status.


% * explain which benchmark modes? will be tested and why 
%   - inserts - very realistic for iot usage where a lot of devices share their state/location
We have identified three scenarios for the SUT which we will test.
(1) Data insertion, a scenario where the clients will be sending data to insert to the DDBMS.
By this we want to benchmark how the SUT will perform when multiple clients try insert data i.e., e-scooters deployed in a city reporting their status and location.
Here we find the write throughput metric extremely relevant. (CITY SOME SOURCE)
% * explain which benchmark modes? will be tested and why 
%   - simple queries - important for real time usecases, like users of an app (finding the closest e-scooter)
(2) Simple read queries, in this scenario we try to simulate queries done by the users of a system i.e., people using the e-scooter app to find the closest e-scooters.
In this scenario we benchmark the read throughput, as it is a relevant metric for the clients of the system.
% * explain which benchmark modes? will be tested and why 
%   - complex queries - important for data analysis, to find out patterns and optimizations (e.g.,used by the e-scooter sharing company)
(3) Complex read queries, here we try to simulate a scenario of a complex queries used for analysis and optimizations i.e., queries done by the e-scooter company to find patterns in the traffic to optimize the placement of the e-scooter stations throughout a city or to gain insight into their data.

\subsection{Scalability}
% NOTE: multiple sizes of the cluster will be used (2,3,4,5) to establish scalability pattern
To establish a scalability pattern multiple sizes of a cluster will be run to evaluate the horizontal scalability.
For each cluster size we run a benchmark of \mobilitydbc and CrateDB.

% NOTE: different client amounts, different number of simultaneous connections simulated by the load generator (100, 1000, 10000)
Not only we will test different cluster sizes, but we will also test a different amount of simultanous client connections.
The load generator will be able to simulate varying number of them using threads i.e., 1000 and 10000 connections.
Multiple configurations of amount of clients allow us to check whether the performance of the queries is improved, such as the response time, or the amount of simultaneous connections handled.
This could lead to important findings as some companies may value the performance of the queries for their data analysis more important compared to the simultaneous connections handled.
The latter one may be more important for a company where vast amount of IoT devices connect to the DDBMS at the same time.

